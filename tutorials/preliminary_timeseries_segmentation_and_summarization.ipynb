{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available soynlp == 0.0.492\n",
      "Available politician_news_analyzer == 0.0.1\n",
      "Available politician_news_dataset\n"
     ]
    }
   ],
   "source": [
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "politician_news_dataset 의 News 는 각 카테고리의 뉴스를 일별로 로딩하는 기능을 제공합니다. News.num_docs 에는 날짜 별 뉴스 기사가 저장되어 있습니다. News class 의 더 자세한 사용법은 https://github.com/lovit/politician_news_dataset 의 README 를 확인하세요.\n",
    "\n",
    "DailyStream 은 하루에 발생한 모든 문서를 하나의 문서를 병합한 class 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-01-01 - 2019-03-10: 2224 dates\n"
     ]
    }
   ],
   "source": [
    "from politician_news_dataset import News\n",
    "from soynlp.normalizer import only_hangle_number\n",
    "\n",
    "class DailyStream:\n",
    "    \"\"\"\n",
    "    A doc for a date\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, news, preprocessing=None, verbose=False):\n",
    "        self.news = news\n",
    "        if preprocessing is None:\n",
    "            preprocessing = only_hangle_number\n",
    "        self.preprocessing = preprocessing\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __iter__(self):\n",
    "        n_dates = len(self.news.num_docs)\n",
    "        for i, (date, _) in enumerate(self.news.num_docs):\n",
    "            docs = ' '.join(self.news.get_news(begin_date=date, end_date=date))\n",
    "            docs = only_hangle_number(docs)\n",
    "            yield docs\n",
    "            if self.verbose:\n",
    "                print('\\r{} / {} dates ... '.format(i+1, n_dates), end='')\n",
    "        print('\\rterminated iteration for {0} / {0} dates '.format(n_dates))\n",
    "\n",
    "news = News(category=0) # '김무성' 뉴스\n",
    "num_dates = len(news.num_docs)\n",
    "print('{} - {}: {} dates'.format(news.num_docs[0][0], news.num_docs[-1][0], num_dates))\n",
    "\n",
    "idx_to_date = [date for date, _ in news.num_docs]\n",
    "date_to_idx = {date:idx for idx, date in enumerate(idx_to_date)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NounLMatchTokenizer 는 어절의 L part 에 존재하는 가장 긴 명사만을 선택하는 토크나이저 입니다. 연속된 두 개의 명사는 복합명사로 취급합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['토크나이저', '명사집합', '사전', '명사']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import NounLMatchTokenizer\n",
    "\n",
    "noun_tokenizer = NounLMatchTokenizer(nouns = {'명사', '집합', '사전', '토크나이저'})\n",
    "noun_tokenizer.tokenize('이 토크나이저는 명사집합 사전을 이용하여 어절의 왼쪽에서 명사만 선택합니다')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2013-01-01 - 2019-03-10 (2,224 일) 간의 뉴스 집합에서 명사를 추출한 뒤, 이를 이용하여 토크나이저를 만듭니다. 그 뒤, 이를 이용하여 일자 별 Bag-of-Words Model 을 학습합니다.\n",
    "\n",
    "이 작업도 약 10 분의 계산 시간과 5GB 에 가까운 메모리가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] use default predictors\n",
      "[Noun Extractor] num features: pos=3929, neg=2321, common=107\n",
      "[Noun Extractor] counting eojeols\n",
      "terminated iteration for 2224 / 2224 dates \n",
      "[EojeolCounter] n eojeol = 1435928 from 2224 sents. mem=0.355 Gb                    \n",
      "[Noun Extractor] complete eojeol counter -> lr graph\n",
      "[Noun Extractor] has been trained. #eojeols=57572836, mem=2.968 Gb\n",
      "[Noun Extractor] batch prediction was completed for 383950 words\n",
      "[Noun Extractor] checked compounds. discovered 341050 compounds\n",
      "[Noun Extractor] postprocessing detaching_features : 65307 -> 63066\n",
      "[Noun Extractor] postprocessing ignore_features : 63066 -> 62668\n",
      "[Noun Extractor] postprocessing ignore_NJ : 62668 -> 61279\n",
      "[Noun Extractor] 61279 nouns (341050 compounds) with min frequency=10\n",
      "[Noun Extractor] flushing was done. mem=3.530 Gb                    \n",
      "[Noun Extractor] 78.66 % eojeols are covered\n",
      "terminated iteration for 2224 / 2224 dates \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2224, 227577)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.noun import LRNounExtractor_v2\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# train noun extractor\n",
    "daily_stream = DailyStream(news, verbose=True)\n",
    "noun_extractor = LRNounExtractor_v2()\n",
    "noun_scores = noun_extractor.train_extract(daily_stream, min_noun_frequency=10)\n",
    "noun_scores = {n:s for n,s in noun_scores.items() if len(n) > 1}\n",
    "\n",
    "# build tokenizer\n",
    "noun_tokenizer = NounLMatchTokenizer(noun_scores)\n",
    "\n",
    "# vectorize\n",
    "vectorizer = CountVectorizer(tokenizer=noun_tokenizer.tokenize)\n",
    "x = vectorizer.fit_transform(daily_stream)\n",
    "vocab_to_idx = vectorizer.vocabulary_\n",
    "idx_to_vocab = [vocab for vocab, idx in sorted(vocab_to_idx.items(), key=lambda x:x[1])]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "politician_news_analyzer 안에는 단어 등장 빈도를 이용하는 키워드 추출 함수와 KR-WordRank 의 핵심 문장 추출 함수가 구현되어 있습니다. 이를 이용하여 begin_date 부터 end_date 기간의 뉴스를 요약하는 함수를 만듭니다.\n",
    "\n",
    "margin 은 begin_date 보다 margin 일 만큼 이전의, end_date 보다 margin 일 만큼 이후의 뉴스를 reference documents 로 이용한다는 의미입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from politician_news_analyzer.summarizer import proportion_keyword\n",
    "from politician_news_analyzer.summarizer import diverse_keysentences\n",
    "\n",
    "def summarize(begin_date, end_date, margin=15, topk1=100, topk2=30, num_sents=5):\n",
    "    n_dates = len(idx_to_date)\n",
    "\n",
    "    def find_idx(date):\n",
    "        for i, date_i in enumerate(idx_to_date[:-1]):\n",
    "            if (date_i <= date < idx_to_date[i+1]):\n",
    "                return i\n",
    "        return n_dates - 1\n",
    "\n",
    "    bdate = find_idx(begin_date)\n",
    "    edate = find_idx(end_date)\n",
    "    pos_idx = [d for d in range(bdate, edate + 1)]\n",
    "    ref_idx = [d for d in range(max(0, bdate - margin), bdate)]\n",
    "    ref_idx += [d for d in range(edate + 1, min(edate + 1 + margin, n_dates))]\n",
    "\n",
    "    keywords = proportion_keyword(x, pos_idx, idx_to_vocab, ref_idx, topk1, topk2)\n",
    "    keyword_score = {w:s for w,s,_ in keywords}\n",
    "\n",
    "    docs = news.get_news(begin_date, end_date)\n",
    "    raw_sents = [sent for doc in docs for sent in doc.split('  ')]\n",
    "    sents = [only_hangle_number(sent) for sent in raw_sents]\n",
    "\n",
    "    keysents = diverse_keysentences(keyword_score, sents, num_sents, raw_texts=raw_sents, diversity=0.5)\n",
    "    return keywords, keysents\n",
    "\n",
    "def print_summary(begin_date, end_date, keywords, keysents):\n",
    "    keywords_ = ', '.join(word for word, _, _ in keywords)\n",
    "    print('{} - {}\\n'.format(begin_date, end_date))\n",
    "    print('[Keywords]\\n{}\\n'.format(keywords_))\n",
    "    print('[Key-sentences]')\n",
    "    for sent in keysents:\n",
    "        print(' - {}'.format(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2017-05-24 에는 '노룩패스' 사건이 있었고, 다음날부터 이 사건에 대한 기사가 주를 이뤘습니다. 이와 관련된 키워드와 핵심 문장이 선택되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-25 - 2017-05-26\n",
      "\n",
      "[Keywords]\n",
      "정관용, 정두언, 유병재, 김현정, 패러디, 25일, 공항, 노룩패스, 소개, 영상, 화제, 패스, 정유라, 공개, 캐리어, 24일, 정치인, 1년, 행동, 이들, 입국, 반납, 세비, 수행원, 장면, 한국, 사진, 이야기, 이낙연, 자신\n",
      "\n",
      "[Key-sentences]\n",
      " - 농구 경기에서 상대편 수비수를 속이기 위해 다른 방향을 보면서 공을 넘기는 동작. ‘노룩패스’(No Look Pass)다. 바른정당의 김무성 의원이 어제 온종일 ‘노룩패스’의 주인공이 돼 인터넷을 후끈 달궜다. 일본 여행에서 돌아온 김 의원이 공항에서 찍힌 몇 초간의 동영상 때문이다. 김 의원은 입국장에 들어서면서 수행비서를 쳐다보지도 않고 걷는 속도를 유지한 채 캐리어를 한 손으로 휙 밀어 정확히 전달에 성공(?)했다. 화면 안으로 잽싸게 뛰어든 수행원이 깔끔하게 캐리어를 받는 장면은 사전 연습이나 한 듯 익숙했다.덕분에 아침 일찍부터 김 의원은 실시간 검색어 선두를 달렸다. 뒤를 안 보고도 공을 뒤로 패스하는 ‘비하인드백패스’(Behind Back Pass)까지 덩달아 인기 검색어로 떴다. 해외 온라인 커뮤니티들에서도 화제였다. 구글, 페이스북, 트위터에 이은 인기 커뮤니티 레딧은 ‘한국 정치인의 스웨그(Swag?허세)’라고 꼬집었다. 어느 온라인 쇼핑몰은 문제의 캐리어를 ‘노룩패스 가방’이라며 홍보했다.\n",
      " - 공개된 영상에는 유병재가 공항 문을 나오면서 스태프로 보이는 사람에게 자신의 캐리어를 굴려 전달하는 모습이 담겨 있다. 김 의원의 ‘캐리어 노 룩 패스’를 패러디한 것으로 해당 영상은 25일 오전 11시 현재, 17만 명이 넘는 네티즌들이 페이스북 ‘공감’을 누르는 등 큰 관심을 끌고 있다.\n",
      " - 방송인 유병재의 ‘노룩패스’ 패러디 영상이 화제를 모으고 있다.\n",
      " - 지미 펄론은 지난 24일(현지시각) 방송된 미국 NBC ‘지미 팰런의 투나잇 쇼’(The Tonight Show Starring Jimmy Fallon)에서 김무성 의원의 ‘노 룩 패스’ 동영상을 소개했다. 그는 영상에 대해 “매우 멋지다” “사람들은 그의 입국 모습이 가장 멋지다고 생각할 것”이라고 말했다. 그는 음악에 맞춰 김 의원이 캐리어를 밀어 건네는 동작을 흉내냈다.\n",
      " - 꼼수일까, 정수일까?). 디지털 세상에서는 이들의 공약이 제대로 지켜지지 않은 만큼 ‘대한민국과의 계약’에서 밝힌 대로 세비를 반납해야 한다는 여론이 일고 있다. 각종 인터넷 커뮤니티에는 48명까지 서명(지난해 4월1일 기준)했던 더 앞선 날짜의 신문 광고 사진이 올라 있다. 누리꾼들은 “6일 남았으니까 6일 후에 1년치 세비 꼭 반납하세요. 지켜보고 있습니다”(아이디 whit****) “세비 반납 안하면 허위사실 공표에 의한 부정선거로 고소해서 의원직 박탈시켜야 한다”(andy****) “약속을 지키는 애국보수인데 당연히 약속한 세비 반납 지킬 거라 믿습니다”(chin****) “보나마나 ‘노룩패스’하겠지. 돈을 차떼기로 끌어 모으는 돈밖에 모르는 족속들인데”(skid****) 등의 반응을 보였다.\n"
     ]
    }
   ],
   "source": [
    "begin_date = '2017-05-25'\n",
    "end_date = '2017-05-26'\n",
    "\n",
    "keywords, keysents = summarize(begin_date, end_date)\n",
    "print_summary(begin_date, end_date, keywords, keysents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018-06-15 ~ 2018-06-22 에는 자유한국당 의원 간의 총선 출마에 관련된 논쟁들이 있던 시기입니다. 이들에 대한 키워드와 핵심 문장이 선택되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-15 - 2018-06-22\n",
      "\n",
      "[Keywords]\n",
      "혁신안, 중앙당, 해체, 선언, 메모, 불출마, 중진, 초선, 혁신, 참패, 잘못, 정당, 쇄신, 의원총회, 국민들, 탄핵, 앞으로, 이번, 논의, 보수, 총선, 의총, 상당, 당의, 갈등, 지적, 바른미래당, 대해서, 어떤, 권한대행\n",
      "\n",
      "[Key-sentences]\n",
      " - 한국당은 15일 오후 국회에서 비상 의원총회를 열어 새 지도부 선출을 비롯한 당의 진로를 논의했다. 김성태 원내대표는 이날 공개발언에서 “우리 당이 처한 정치생태계를 바꿔야 새로운 세력이 등장하고 새로운 도전도 가능해진다”며 “물러날 분들은 뒤로 물러나고 확실한 세대교체를 이뤄야 한다”고 강조했다. 한국당의 상황은 그러나 김 원내대표의 말과는 반대로 가고 있다. 지적만 난무할 뿐 ‘내가 잘못했으니···’라는 인정과 책임은 찾아보기 어렵다. 이번 사태를 1인칭에서 바라봐야 할 당사자들이 3인칭 관찰자 시점에 머물러 있는 셈이다. 실제로 차기 당권 주자로 거론되는 중진들은 잇따라 반성문을 쏟아냈다. 5선의 심재철 의원은 페이스북에 “남은 것은 통렬한 자기반성과 철저한 자기혁신밖에 없다”고 주장했고 4선의 정우택 의원은 “보수는 죽었다. 무엇을 바꿔야 하는지 돌이켜보고 가슴에 새겨 실천하겠다”고 밝혔다. 4선인 나경원 의원 역시 “당과 보수가 잘못된 길을 가는데도 더 용기 있게 말하지 못한 것을 반성한다”며 “모두 버리고 새로 시작해야 한다”고 강조했다. 초선 의원들은 중진들이 당면과제에 뒷짐 지고 있다며 공개 비판에 나섰다. 김순례·김성태(비례)·성일종·이은권·정종섭 의원은 기자회견을 열어 “10년간 보수정치의 실패에 책임이 있는 중진들은 정계 은퇴를 하고 당을 제대로 이끌지 못한 중진은 당 운영의 전면에 나서지 말라”고 요구했다. 특정 의원을 지칭하지는 않았지만 계파싸움에 골몰하며 내홍을 부추겨온 중진을 싸잡아 비판한 것으로 보인다. 이 같은 내분을 두고 정치권에서는 “한국당 의원들이 ‘잘못도 했고 희생도 해야 하는데 그게 나는 아니다’라는 인식에 사로잡혀 있다”는 비아냥까지 나온다. 한편 김무성 의원은 이날 의총에서 “당 재건을 위해 나부터 내려놓겠다”며 21대 총선 불출마를 선언했다. 다만 차기 당 대표 출마에 대해서는 언급하지 않았다.\n",
      " - 김성태 당대표 권한대행이 지난 18일 기자회견을 열어 제안한 지방선거 참패 수습책에 대해서다. 김 권한대행은 당시 중앙당 해체 및 원내중심정당 건설, 그리고 외부인사를 위원장으로 하는 혁신 전권 비상대책위원회 구성 등을 골자로 한 '혁신안'을 내놨다. 그러나 곧장 반발이 일었다. 일부 재선 의원들은 이를 '단독 플레이'로 규정짓고 의원총회를 소집했다.(관련 기사 : '혁신 폭탄' 던진 김성태 \"지금 이 순간부터 중앙당 해체 돌입\") 이러한 가운데, 중진 의원들마저 고개를 내젓고 나선 셈이다.\n",
      " - 이런 상황에서 김 원내대표는 “이번 선거는 국민이 한국당을 탄핵한 선거”라며 “여전히 수구 냉전적 사고에 머무른다면 국민이 더 외면할 것이란 경고를 잘 새겨들어야 한다”고 강조했다. 그는 “보수이념의 해체, 한국당 해체를 통해 처음부터 다시 시작해야 한다”며 “국민들로부터 탄핵당한 마당에 조기 전당대회, 비상대책위원회 구성을 논의할 상황이 아니다”라고 질타했다. 3시간 40분여 진행된 의원총회가 끝나고 한국당 의원들은 참패에 대해 공식 사과하며 무릎을 꿇었다. 김 원내대표는 “조기 전당대회는 대체로 지금 상황에서 치러서는 안 된다는 분위기였다”며 “앞으로 혁신 비대위를 구성해서 당의 변화에 새로운 리더십을 만들어 가겠다”고 설명했다.\n",
      " - ‘박성중 메모’ 문제로 잘잘못을 따지다 보니 정작 논의해야 할 쇄신안 문제는 테이블에 오르지도 못했다. 신상진 의원은 “의총은 결론 없이 끝났다”면서 “민주적 절차가 부족했다는 비판이 있었고 내용에서도 ‘중앙당 슬림화가 무슨 혁신이냐’, ‘우리당 어려움이 그것 때문에 생긴 게 아니다’라는 지적들도 있었다”고 전했다. 김 권한대행은 의총이 끝난 뒤 자신을 향한 사퇴요구에 대해 \"그런 목소리도 있었다\"면서도 \"당내 갈등을 유발하고 분열을 자초하는 것은 어떤 경우든 용납하지 않겠다”고 답했다.\n",
      " - 일단 이번의 선거결과에 대해서 제가 볼 때는 두 가지 사실이 아닌 그런 얘기가 특히 여당 쪽에서 나오고 그 여당의 얘기를 받아서 자유한국당 내에서도 자학 비슷하게 얘기하는 사람들이 있는데 하나는 이번에 자유한국당은 궤멸했다, 또 하나는 궤멸한 이유는 우리가 소위 말하면 시대적인 변화를 못 일궈내고 남북화해무드를 거슬러가고 그다음에 소위 말하는 기득권 계보를 옹호하기 때문에 그랬다, 라는 얘기를 하는 사람들이 안팎으로 많아요. 그래서 제가 거기에 대해서 단순히 감정적인 게 아니라 객관적인 사실이 그렇지 않다, 라는 것을 말하기 위해서 저희 한국당이 과거 1년 전 대선에 비해서는 아주 더디게 회복하고 있다, 물론 회복하다가 도로 고꾸라질 수도 있어요. 그러나 원인은 분명히 알아야 된다. 그리고 또 하나는 우리가 무슨 예를 들어서 남북화해무드에 대해서 반대하는 것도 아니고, 다만, 김정은을 그렇게 철석같이 믿지 말라, 이렇게 문제제기하는 거라는 측면을 저는 강조하고 싶었기 때문인데 최근에 이런 저희의 패배와 관련해서 김성태 의원을 중심으로 해서 상당히 아주 파격적인 안을 냈는데 예를 들어서 중앙당 해체, 이것은 제가 볼 때는 장기적으로 우리나라 정당이 가야 할 방향이에요. 그런데 미국의 정당구조가 그렇게 되는데 그것은 장기적으로 가야 할 방향이지, 최근의 패배, 대선 이후의 패배의 원인은 아니거든요. 그러면 똑같이 중앙당 중심인 저기 민주당도 망했어야 되는데 망하지 않았잖아요. 그러니까 이것은 원인진단을 잘못한 거고 그래서 지금 우리가 오히려 정확하게 원인 진단을 해서 대책을 구하려면 사실은 저는 그렇게 생각해요. 첫 번째는 우리 당의 지도부가 아직도 국민들이 보기에는 탄핵의 여러 가지 원인제공자로서 섭섭한 모습, 그런 응어리를 못 풀어드렸기 때문에 그렇다, 그것을 풀어드려야 된다.\n"
     ]
    }
   ],
   "source": [
    "begin_date = '2018-06-15'\n",
    "end_date = '2018-06-22'\n",
    "\n",
    "keywords, keysents = summarize(begin_date, end_date)\n",
    "print_summary(begin_date, end_date, keywords, keysents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "물론 이 방법이 news stream 을 제대로 요약하는 방법은 아닙니다만, 큰 흐름을 설명할 수 있는 키워드와 핵심 문장은 위의 간단한 코드로 추출할 수 있습니다. 또한 politician news dataset 을 이용하는 연습을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
